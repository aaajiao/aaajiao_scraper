#!/usr/bin/env python3
"""
Quick Start Example - aaajiao Portfolio Scraper

å±•ç¤ºåŸºæœ¬ä½¿ç”¨æµç¨‹ï¼šåˆå§‹åŒ–ã€çˆ¬å–ã€å¯¼å‡º
"""

from scraper import AaajiaoScraper


def main():
    """åŸºç¡€ä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸš€ aaajiao ä½œå“çˆ¬è™« - å¿«é€Ÿå¼€å§‹\n")
    
    # 1. åˆå§‹åŒ–çˆ¬è™«ï¼ˆè‡ªåŠ¨ä».envåŠ è½½API keyï¼‰
    print("ğŸ“¦ åˆå§‹åŒ–çˆ¬è™«...")
    scraper = AaajiaoScraper(use_cache=True)
    
    # 2. è·å–æ‰€æœ‰ä½œå“é“¾æ¥ï¼ˆåŸºç¡€æ¨¡å¼ï¼‰
    print("\nğŸ” ä» sitemap è·å–ä½œå“é“¾æ¥...")
    work_urls = scraper.get_all_work_links(incremental=False)
    print(f"   æ‰¾åˆ° {len(work_urls)} ä¸ªä½œå“")
    
    # 3. æå–å•ä¸ªä½œå“è¯¦æƒ…ï¼ˆAI æ¨¡å¼ï¼‰
    if work_urls:
        print("\nğŸ¨ æå–ç¬¬ä¸€ä¸ªä½œå“çš„è¯¦æƒ…...")
        first_url = work_urls[0]
        work_data = scraper.extract_work_details(first_url)
        
        if work_data:
            print(f"   âœ… æˆåŠŸæå–ï¼š{work_data.get('title', 'Unknown')}")
            print(f"   ğŸ“… å¹´ä»½ï¼š{work_data.get('year', 'N/A')}")
            print(f"   ğŸ·ï¸  ç±»å‹ï¼š{work_data.get('category', 'N/A')}")
        else:
            print("   âŒ æå–å¤±è´¥")
    
    # 4. å¯¼å‡ºç»“æœ
    print("\nğŸ’¾ å¯¼å‡ºç»“æœ...")
    if scraper.works:
        scraper.save_to_json("output/quick_start_results.json")
        scraper.generate_markdown("output/quick_start_portfolio.md")
        print("   âœ… å·²ä¿å­˜åˆ° output/ ç›®å½•")
    else:
        print("   âš ï¸  æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
    
    print("\nâœ¨ å®Œæˆï¼")


if __name__ == "__main__":
    main()
