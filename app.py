import streamlit as st
import time
import pandas as pd
import json
import os
from aaajiao_scraper import AaajiaoScraper
import concurrent.futures

# é…ç½®é¡µé¢
st.set_page_config(
    page_title="aaajiao Scraper",
    page_icon="ğŸ¨",
    layout="wide"
)

# æ ‡é¢˜
st.title("ğŸ¨ aaajiao ä½œå“é›†æŠ“å–å·¥å…·")
st.markdown("æ­¤å·¥å…·å¯ä»¥ä» eventstructure.com è‡ªåŠ¨æŠ“å–ä½œå“ä¿¡æ¯å¹¶ç”Ÿæˆæ–‡æ¡£ã€‚")

# åˆå§‹åŒ– session state
if 'works' not in st.session_state:
    st.session_state.works = []
if 'scraping' not in st.session_state:
    st.session_state.scraping = False
if 'log_messages' not in st.session_state:
    st.session_state.log_messages = []

def run_scraper():
    st.session_state.scraping = True
    st.session_state.works = []
    st.session_state.log_messages = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    log_area = st.empty()
    
    try:
        scraper = AaajiaoScraper()
        
        # 1. è·å–é“¾æ¥
        status_text.text("æ­£åœ¨è·å–ä½œå“åˆ—è¡¨...")
        st.session_state.log_messages.append("æ­£åœ¨æ‰«æä¸»é¡µè·å–é“¾æ¥...")
        links = scraper.get_all_work_links()
        total_links = len(links)
        st.session_state.log_messages.append(f"æ‰¾åˆ° {total_links} ä¸ªä½œå“é“¾æ¥")
        
        # 2. å¹¶å‘æŠ“å–
        if total_links > 0:
            with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
                future_to_url = {executor.submit(scraper.extract_work_details, url): url for url in links}
                
                completed_count = 0
                for future in concurrent.futures.as_completed(future_to_url):
                    url = future_to_url[future]
                    completed_count += 1
                    
                    try:
                        data = future.result()
                        if data:
                            st.session_state.works.append(data)
                            msg = f"[{completed_count}/{total_links}] æˆåŠŸ: {data.get('title', 'Unknown')}"
                        else:
                            msg = f"[{completed_count}/{total_links}] å¤±è´¥: {url}"
                            
                        st.session_state.log_messages.append(msg)
                        
                        # æ›´æ–°UI
                        progress = completed_count / total_links
                        progress_bar.progress(progress)
                        status_text.text(f"æ­£åœ¨æŠ“å–: {completed_count}/{total_links}")
                        
                        # ä»…æ˜¾ç¤ºæœ€è¿‘5æ¡æ—¥å¿—ä»¥å…åˆ·å±
                        log_area.code("\n".join(st.session_state.log_messages[-5:]))
                        
                    except Exception as e:
                        st.session_state.log_messages.append(f"é”™è¯¯: {e}")

        # 3. ä¿å­˜æ–‡ä»¶
        status_text.text("æ­£åœ¨ä¿å­˜æ–‡ä»¶...")
        # æ­¤æ—¶ works å·²ç»å¡«å……åˆ° scraper å®ä¾‹ä¸­äº†å—ï¼Ÿæ²¡æœ‰ï¼Œæˆ‘ä»¬æ‰‹åŠ¨èµ‹å€¼
        scraper.works = st.session_state.works
        
        scraper.save_to_json()
        scraper.generate_markdown()
        
        st.success(f"æŠ“å–å®Œæˆï¼å…±è·å– {len(st.session_state.works)} ä¸ªä½œå“ã€‚")
        st.balloons()
        
    except Exception as e:
        st.error(f"å‘ç”Ÿé”™è¯¯: {str(e)}")
    finally:
        st.session_state.scraping = False

# æŒ‰é’®åŒºåŸŸ
col1, col2 = st.columns([1, 4])
with col1:
    if st.button("ğŸš€ å¼€å§‹æŠ“å–", disabled=st.session_state.scraping, type="primary"):
        run_scraper()

# ç»“æœå±•ç¤ºåŒºåŸŸ
if st.session_state.works:
    st.divider()
    st.subheader("ğŸ“Š æŠ“å–ç»“æœé¢„è§ˆ")
    
    # è½¬ä¸º DataFrame å±•ç¤º
    df = pd.DataFrame(st.session_state.works)
    # é€‰å–ä¸»è¦åˆ—å±•ç¤º
    display_cols = ['title', 'title_cn', 'year', 'type', 'url']
    cols_to_show = [c for c in display_cols if c in df.columns]
    st.dataframe(df[cols_to_show], use_container_width=True)
    
    st.divider()
    st.subheader("ğŸ“¥ ä¸‹è½½æ–‡ä»¶")
    
    c1, c2 = st.columns(2)
    with c1:
        # è¯»å–ç”Ÿæˆçš„æ–‡ä»¶ä¾›ä¸‹è½½
        try:
            with open("aaajiao_works.json", "rb") as f:
                st.download_button(
                    label="ä¸‹è½½ JSON æ•°æ®",
                    data=f,
                    file_name="aaajiao_works.json",
                    mime="application/json"
                )
        except FileNotFoundError:
            st.warning("JSON æ–‡ä»¶å°šæœªç”Ÿæˆ")
            
    with c2:
        try:
            with open("aaajiao_portfolio.md", "rb") as f:
                st.download_button(
                    label="ä¸‹è½½ Markdown æ–‡æ¡£",
                    data=f,
                    file_name="aaajiao_portfolio.md",
                    mime="text/markdown"
                )
        except FileNotFoundError:
            st.warning("Markdown æ–‡ä»¶å°šæœªç”Ÿæˆ")

elif not st.session_state.scraping:
    st.info("ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®å¼€å§‹è¿è¡Œã€‚")

# ä¾§è¾¹æ ï¼šé€€å‡ºåŠŸèƒ½
with st.sidebar:
    st.markdown("### æ§åˆ¶å°")
    if st.button("âŒ é€€å‡ºç¨‹åº"):
        st.warning("ç¨‹åºæ­£åœ¨é€€å‡º...æ‚¨å¯ä»¥å…³é—­æ­¤æµè§ˆå™¨æ ‡ç­¾é¡µäº†ã€‚")
        # ç»™ä¸€ç‚¹æ—¶é—´è®©ä¸Šé¢çš„æç¤ºæ¸²æŸ“å‡ºæ¥
        time.sleep(1)
        os._exit(0)
