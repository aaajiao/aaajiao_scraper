
import os
import json
import logging
import requests
from typing import Dict, Any, List
from datetime import datetime
from .constants import BASE_URL

logger = logging.getLogger(__name__)

class ReportMixin:
    """Reporting functionalities"""
    
    def save_to_json(self, filename: str = 'aaajiao_works.json'):
        """ä¿å­˜ä½œå“æ•°æ®åˆ° JSON"""
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.works, f, ensure_ascii=False, indent=2)
        logger.info(f"JSON æ•°æ®å·²ä¿å­˜: {filename} ({len(self.works)} works)")

    def generate_markdown(self, filename: str = 'aaajiao_portfolio.md'):
        """ç”Ÿæˆ Markdown æ ¼å¼çš„ä½œå“é›†æ–‡æ¡£ (Basic Scraper)"""
        lines = [
            "# aaajiao ä½œå“é›† / aaajiao Portfolio\n",
            f"Source: {BASE_URL}\n",
            "Generated by aaajiao Scraper v3 (Firecrawl Edition)\n",
            "\n---\n\n"
        ]
        
        # Sort by year
        sorted_works = sorted(self.works, key=lambda x: x.get('year') or '0000', reverse=True)
        
        current_year = None
        for work in sorted_works:
            year = work.get('year', 'Unknown')
            if year != current_year:
                lines.append(f"## {year}\n\n")
                current_year = year
                
            title = work.get('title', 'Untitled')
            title_cn = work.get('title_cn', '')
            
            header = f"### [{title}]({work['url']})"
            if title_cn:
                header += f" / {title_cn}"
            lines.append(header + "\n\n")
            
            if work.get('type'): 
                lines.append(f"**Type**: {work['type']}\n\n")
            if work.get('materials'):
                lines.append(f"**Materials**: {work['materials']}\n\n")
            if work.get('video_link'): 
                lines.append(f"**Video**: {work['video_link']}\n\n")
            
            if work.get('description_cn'):
                lines.append(f"> {work['description_cn']}\n\n")
                
            if work.get('description_en'):
                lines.append(f"{work['description_en']}\n\n")
                 
            lines.append("---\n")
            
        with open(filename, 'w', encoding='utf-8') as f:
            f.write("".join(lines))
        
        logger.info(f"Markdown æ–‡ä»¶å·²ç”Ÿæˆ: {filename}")

    def generate_agent_report(self, data: Dict[str, Any], output_dir: str, prompt: str = "", extraction_level: str = "custom"):
        """
        æ ¹æ® Agent è¿”å›çš„æ•°æ®ç”Ÿæˆ Markdown æŠ¥å‘Šå’Œä¸‹è½½å›¾ç‰‡
        """
        
        os.makedirs(output_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        logger.info(f"ğŸ“ ç”ŸæˆæŠ¥å‘Šåˆ°: {output_dir}")
        
        # è§£ææ•°æ®åˆ—è¡¨
        data_list = data.get("data", [data]) if isinstance(data, dict) else [data]
        if not isinstance(data_list, list):
            data_list = [data_list]
        
        # 1. åˆ›å»ºå›¾ç‰‡ç›®å½•å¹¶ä¸‹è½½æ‰€æœ‰å›¾ç‰‡ï¼Œå»ºç«‹ URL -> æœ¬åœ°è·¯å¾„æ˜ å°„
        images_dir = f"images_{timestamp}"
        images_path = os.path.join(output_dir, images_dir)
        os.makedirs(images_path, exist_ok=True)
        
        url_to_local = {}  # URL -> ç›¸å¯¹è·¯å¾„æ˜ å°„
        img_counter = 0
        
        for item in data_list:
            if not isinstance(item, dict):
                continue
            images = item.get("high_res_images") or item.get("images") or []
            for img_url in images:
                if img_url in url_to_local:
                    continue  # å·²ä¸‹è½½
                img_counter += 1
                try:
                    ext = os.path.splitext(img_url.split("?")[0])[-1] or ".jpg"
                    if not ext.startswith("."):
                        ext = ".jpg"
                    local_filename = f"{img_counter:02d}{ext}"
                    local_path = os.path.join(images_path, local_filename)
                    
                    resp = requests.get(img_url, timeout=30)
                    if resp.status_code == 200:
                        with open(local_path, "wb") as f:
                            f.write(resp.content)
                        url_to_local[img_url] = f"{images_dir}/{local_filename}"
                        logger.info(f"ğŸ“¥ ä¸‹è½½å›¾ç‰‡ [{img_counter}]: {local_filename}")
                except Exception as e:
                    logger.warning(f"å›¾ç‰‡ä¸‹è½½å¤±è´¥: {img_url[:50]}... - {e}")
        
        logger.info(f"âœ… æˆåŠŸä¸‹è½½ {len(url_to_local)} å¼ å›¾ç‰‡")
        
        # 2. ç”Ÿæˆ Markdown æŠ¥å‘Š
        report_filename = f"report_{timestamp}.md"
        report_path = os.path.join(output_dir, report_filename)
        
        lines = []
        
        # æŠ¥å‘Šå¤´éƒ¨
        lines.append("# ä½œå“æå–æŠ¥å‘Š\n\n")
        lines.append(f"> **æå–æ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M')}\n")
        lines.append(f"> **æå–æ¨¡å¼:** {extraction_level.upper()}\n")
        lines.append(f"> **ä½œå“æ•°é‡:** {len(data_list)}\n")
        lines.append("\n---\n\n")
        
        # æ¯ä¸ªä½œå“ä¸€ä¸ªç« èŠ‚
        for i, item in enumerate(data_list, 1):
            if not isinstance(item, dict):
                continue
            
            title = item.get("title", f"ä½œå“ {i}")
            title_cn = item.get("title_cn", "")
            year = item.get("year", "")
            
            if title_cn and title_cn != title:
                lines.append(f"## {i}. {title} / {title_cn}\n\n")
            else:
                lines.append(f"## {i}. {title}\n\n")
            
            # å±æ€§åˆ—è¡¨
            if year:
                lines.append(f"| å¹´ä»½ | {year} |\n")
            if item.get("category") or item.get("type"):
                lines.append(f"| ç±»å‹ | {item.get('category') or item.get('type')} |\n")
            if item.get("video_link"):
                lines.append(f"| è§†é¢‘ | [{item['video_link']}]({item['video_link']}) |\n")
            if item.get("materials"):
                lines.append(f"| ææ–™ | {item['materials']} |\n")
            lines.append("\n")
            
            # æè¿°
            desc_en = item.get("description_en") or item.get("description", "")
            desc_cn = item.get("description_cn", "")
            
            if desc_en or desc_cn:
                lines.append("### Description / æè¿°\n\n")
                if desc_en:
                    lines.append(f"**English:**\n\n{desc_en}\n\n")
                if desc_cn:
                    lines.append(f"**ä¸­æ–‡:**\n\n{desc_cn}\n\n")
            
            # å›¾ç‰‡ï¼ˆä½¿ç”¨æœ¬åœ°ç›¸å¯¹è·¯å¾„ï¼‰
            images = item.get("high_res_images") or item.get("images") or []
            if images:
                lines.append("### å›¾ç‰‡\n\n")
                for img_url in images[:6]:
                    local_rel_path = url_to_local.get(img_url)
                    if local_rel_path:
                        lines.append(f"![]({local_rel_path})\n\n")
                    else:
                        lines.append(f"![]({img_url})\n\n")  # fallback to URL
            
            lines.append("---\n\n")
        
        # å†™å…¥æ–‡ä»¶
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("".join(lines))
        
        logger.info(f"ğŸ“„ Markdown æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        
        # åŒæ—¶ä¿å­˜åŸå§‹ JSON
        json_filename = f"data_{timestamp}.json"
        json_path = os.path.join(output_dir, json_filename)
        
        output_data = {
            "_meta": {
                "prompt": prompt,
                "extraction_level": extraction_level,
                "timestamp": datetime.now().isoformat()
            },
            "data": data_list,
            # Pass through stats if available in data
            "cached_count": data.get("cached_count", 0) if isinstance(data, dict) else 0,
            "new_count": data.get("new_count", 0) if isinstance(data, dict) else 0 # simple logic
        }
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
            
        return report_path
